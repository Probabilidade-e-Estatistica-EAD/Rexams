---
title: "Pôster: Geração aleatória e correção automática de questões através do `R`/`exams`"
# author: "Markus Stein"
date: "Julho 2022"
output: pdf_document
    # toc: yes
header-includes:
    - \usepackage{fancyhdr}
always_allow_html: yes
---
\addtolength{\headheight}{1.0cm}
\pagestyle{fancyplain} 
\lhead{\includegraphics[height=1.5cm]{imagens/logoIME.png}}
\rhead{\includegraphics[height=1.5cm]{imagens/logoEAD.png}}
<!-- \chead{UNIVERSIDADE FEDERAL DO RIO GRANDE DO SUL \\ -->
<!-- INSTITUTO DE MATEMÁTICA E ESTATÍSTICA \\ -->
<!-- DEPARTAMENTO DE ESTATÍSTICA \\ -->
<!-- \vspace{0.3cm} -->
<!-- MAT02219 - Probabilidade e Estatística - 2021/2 -->
<!-- } -->
\renewcommand{\headrulewidth}{0pt} 


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introdução
* Planejar e executar avaliações é um dos grandes desafios no processo de ensino e aprendizagem. 
	+ Em turmas de ensino à distância (EAD) esse aspecto necessita de maior atenção. 

* Importante criar mecanismos avaliativos que evitem a repetição de questões entre os alunos e inibam potenciais cópias/plágios. 
	
* Se destacam a criação de questões e a sua correção, bem como a análise dos resultados e o retorno da avaliação ao estudante.

* No nosso Departamento as turmas EAD de Probabilidade e Estatística atendem entre 300 e 400 alunos nos últimos semestres. ufrgs.br/probabilidade-estatistica 

## Porque `R` e o pacote `exams`?
* Utilizar o conhecimento em `R` para auxiliar na criação de questões aleatorizadas.

* Aproveitar as facilidades do formato de arquivos `Rmarkdown` (integrar códigos em `R` e texto).

* Possibilidade de gerar provas impressas ou online, com correção automática.

## Motivação
* Mecanismos que auxiliem na elaboração e correção automática das avaliações possibilitam que professores tenham mais tempo para planejar o instrumento de avaliação e analisar o desempenho da turma.

* A criação das questões é parte essencial no processo de flexibilização das avaliações e exige conhecimento de programação, no software `R`, pacotes `Markdown`, linguagem `Latex` e da teoria estatística envolvida.

## Contribuições
* Criação do banco de questões no formato `exams`, códigos em `R` para geração e correção automática de avaliações, no formato impresso ou `XML`.

* Otimização do processo de avaliação, com o auxílio de recursos que minimizem atividades repetitivas na geração, correção, análise e divulgação dos resultados, presenciais ou à distância. 

# Desenvolvimento

## Criação das Questões

* O desenvolvimento das questões é uma tarefa complexa que exige conhecimentos sobre construção de provas múltipla escolha bem como programação no software `R`. 

* Juntamente com a criação dos enunciados e alternativas de respostas, a construção do gabarito da questão já é feita de maneira integrada com o pacote `exams`.

* Diferentes tipos de formatos para respostas: abertas e única/múltipla escolha
	+ formatos do exams: numérica (`numeric`), discursiva (`string`), única escolha (`schoice`), mútiplas escolhas (`mchoice`) e combinações entre os tipos.

\begin{figure}[h]
    \label{figura1}
    \centering
    \includegraphics[width=08cm, height=08cm]{imagens/image-questao-schoice-moodle}
    \includegraphics[width=08cm, height=08cm]{imagens/image-questao-cloze-moodle}
    \caption{Enunciado e o gabarito de uma questão respondida no Moodle no formato `schoice` (esquerda) e no formato `cloze` (direita).}
\end{figure}

* Por fim, estressar/testar as questões, para avaliar possíveis erros e reformulações, pode ser facilitada com a função `stresstest_exercise()`. Apenas as questões que já foram completamente testadas devem compor o banco de questões. 

## Banco de Questões

* A organização das questões é fundamental para a eficiência na criação da avaliações. Um protocolo para criação de questões e inclusão no banco pode auxiliar nessa tarefa.

* Para pré visualizar um questionário/questões: 
    + a função `exams2html()` gera um arquivo `HTML` com a(s) questão(ões); 
    + ou a função `exams2pdf()` gera um arquivo `pdf`, mas precisa ter alguma distribuição `Latex` instalada.

## Questionários

* O `exams` utiliza um objeto `list` com nomes das questões/caminho;
    + cada elemento da lista pode ser um único nome ou vetor de nomes de questões;
    + se for um vetor, a aleatorização também ocorrerá entre diferentes questões.

* Pare gerar avaliações e provas impressas a função `exams2nops(...)` auxiliam no processo.

* para gerar `XML` e aplicar provas remotas, no `Moodle` por exemplo, usar a função `exams2moodle(...)`.
    + Poderíamos criar um arquivo `XML` com códigos puramente em `R` sem usar o exams, porém a estrutura e organização criado pelo exams.

## Correção da avaliação

* Com a utilização do `exams` a correção das avaliações se torna um trabalho puramente mecânico, também no formato impresso.
    + A correção é feita com a leitura das provas feita em qualquer scanner e o reconhecimento das respostas é realizada pelo próprio pacote `exams` através de um software de reconhecimento óptico de caracteres. A Figura \ref{figura2} apresenta o resultado da correção no formato impresso.
    
* Para questões geradas nos formatos digitais, a correção é feita automaticamente após a finalização da atividade, conforme ilustrado na Figura \ref{figura1}.

\begin{figure}[h]
    \label{figura2}
    \centering
    \includegraphics[width=08cm, height=08cm]{imagens/image-capa-prova-impressa-corrigida}
    \caption{Arquivo HTML gerado na correção automática da avaliação impressa (acima) e a folha de respostas preenchida (abaixo).}
\end{figure}

* O retorno da atividade/correção aos estudantes é realizado por envio automático de email com o resultado da avaliação para cada aluno, no formato impresso.  


### **Análise**: comparação da distribuição das notas anteriormente e no período do Ensino Remoto Emergencial (ERE). 

<!-- + As notas de 2019 estão em arquivos separados, de 2020 e 2021 as notas estão no livro de notas das turmas no Moodle. ...precisa organiazr os bancos.. -->
* Podemos considerar cada ano/semestre uma coorte.
    + Em 2019 as avaliações semanais foram online e valiam presença. As provas presenciais, com questões no formato de múltiplas alternativas e única escolha. 
    + Em 2020 e 2021 tivemos o regime de Ensino Remoto Emergencial (ERE e as avaliações semanais valiam nota. As provas foram remotas, sem supervisão, com questões em outros formatos também, como numéricas, ou de associação, sendo incorporadas aos questionários.

* *Ilustração*: O que a distribuição das notas de 2019/2 e 2020/1 nos sugerem? 
    + Uma análise cuidadosa é necessária para concluirmos sobre diferenças nos instrumentos/formatos de avaliações. Estudantes e colaboradora(o)s são bem vinda(o)s.
    + O gráfico abaixo é apenas uma ilustração com dados limitados. Na prova 1 ainda estávamos impementando diferentes formatos do que os de única escolha utilizados nas avaliações presenciais. Ao longo do semestre 2020/1 fomos adotando diferentes formatos de questões, na prova 3 estávamos com mais questões abertas. Como sera a comparacao com semestres anteriores e posteriores ao período ilustrado? 

```{r, echo=FALSE, message=FALSE, fig.height=2.7, fig.width=4.5, fig.align='center'}
library(here)

## dados
# notas 2019/2
notas_prova1_20192 <- read.csv2(here("apresentacoes/dados", "notas_prova1_20192.csv"), sep = ",", header = TRUE, encoding = "UTF-8" )
notas_prova2_20192 <- read.csv2(here("apresentacoes/dados", "notas_prova2_20192.csv"), sep = ",", header = TRUE, encoding = "UTF-8" )
notas_prova3_20192 <- read.csv2(here("apresentacoes/dados", "notas_prova3_20192.csv"), sep = ",", header = TRUE, encoding = "UTF-8" )
notas20192 <- merge(notas_prova2_20192, notas_prova1_20192, by="cartao", all=TRUE)
names(notas20192)[names(notas20192) == "points.x"] <- "prova2"
names(notas20192)[names(notas20192) == "points.y"] <- "prova1"
notas20192 <- merge(notas20192, notas_prova3_20192, by="cartao", all=TRUE) # estão faltando notas da prova 3, tem um arquivo parte2 com os mesmos dados
names(notas20192)[names(notas20192) == "points"] <- "prova3"

# notas 2020/1
notas20201 <- read.csv2(here("apresentacoes/dados", "notas_provas_20201.csv"), sep = ",", header = TRUE, encoding = "UTF-8" )

# juntando bancos
dados <- rbind( cbind(semestre="2019/2", notas20192[,c("prova1", "prova2", "prova3")]), 
                cbind(semestre="2020/1", notas20201[,c("prova1", "prova2", "prova3")]))

## grafico - layout 8 panels
layout(rbind(c(0,2,7,8,0),
             c(4,1,5,6,0),
             c(0,3,3,3,0)),
       height = c(lcm(1), 1, lcm(2)),
       width = c(lcm(2), 1/3, 1/3, 1/3, lcm(0.5)))
#layout.show(3)
#box("outer", lty = "dotted")

# panel 1
par(mar = rep(0, 4), cex = 0.8)
yrange = c(0, 10)
boxplot(prova1 ~ semestre, dados, xlab="", ylab="", ylim=yrange)

# panel 2
plot.new()
text(.5, .5, "Prova 1")

# panel 3
plot.new()
plot.window(xlim = c(0, 1), ylim = c(0, 1))
text(.5, .25, "Semestre", cex = 1, font = 1)

# panel 4
plot.new()
text(.25, .5, "Notas", cex = 1, font = 1, srt = 90)

# panel 5
boxplot(prova2 ~ semestre, dados, xlab="", yaxt="n", ylim=yrange)

# panel 6
boxplot(prova3 ~ semestre, dados, xlab="", yaxt="n", ylim=yrange)

# panel 7
plot.new()
text(.5, .5, "Prova 2")

# panel 8
plot.new()
text(.5, .5, "Prova 3")

# grafico longitudinal???
# https://www.r-bloggers.com/2015/07/line-plots-of-longitudinal-summary-data-in-r-using-ggplot2/
```

Bilgin e Lin (2022) Usam o pacote `exams` para criar questões e comparam o desempenho dos estudantes antes e durante a pandemia causada pela Covid-19. Concluem não haver diferença expressiva nos resultados das avaliações, que os instrumentos foram muito semelhantes na mensuração do conhecimento, sugerindo manter a integridade acadêmica embora no segundo período os testes tenham sido online e sem a supervisão do professor.


# Conclusões
* Facilitar o processo de geração de questões e correção em disciplinas de massa é necessário.

* Colaboração e organização na criação de avaliações e banco de questões também são fundamentais.

* A avaliação
    + **online** tem maior flexibilidade de formatos, porém menor controle. A aleatorização como forma de evitar cópias;plágios
    + **presencial** se torna escalável com baixo custo, a aplicação e geração de avaliações com a leitura óptica economiza muito tempo na correção das avaliações. 
    
* Nas provas impressas, o retorno da prova corrigida para o aluno, via email, faz com que o estudante se sinta mais integrado à disciplina.

* O processo torna a criação, correção e análise dos resultados de avaliações mais eficiente, dessa forma o docente terá uma ferramenta para facilitar na condução da disciplina. 

* É possível criar um processo operacional, para que as ferramentas desenvolvidas sejam estendidas para diferentes formatos de cursos/disciplinas, criar parcerias com outras Universidades, tudo via `R`, software livre e gratuito. 


# Trabalhos futuros 
* Juntamente à análise do desempenho dos alunos podemos aplicar a metodologia de teoria de resposta ao item (TRI), para analisar o grau de dificuldade das questões auxiliando na criação de questões e composição dos questionários.

# Agradecimentos
Ao auxílio da Secretaria de Educação à Distância (SEAD/UFRGS). A(o)s monitora(e)s envolvida(o)s no projeto. 

* **Dúvidas, colaborações e acesso às questões enviar email para...QR code...** 

* [ufrgs.br/probabilidade-estatistica](http://ufrgs.br/probabilidade-estatistica)


# Referências
Achim Zeileis, Nikolaus Umlauf, Friedrich Leisch (2014). Flexible Generation of E-Learning Exams in R: Moodle Quizzes, OLAT Assessments, and Beyond. Journal of Statistical Software 58(1), 1-36.

Ayse Aysin Bilgin, Huan Lin (2022). Designing assessment tasks to prevent cheating in a large first-year statistics unit (2022) Conference paper DOI: 10.52041/iase.errob

Bettina Gruen, Achim Zeileis (2009). Automatic Generation of Exams in R. Journal of Statistical Software 29(10), 1-14

R Core Team (2019). R: A language and environment for statistical computing. R Foundation for  Statistical Computing, Vienna, Austria. URL https://www.R-project.org/.



<!-- \clearpage -->

<!-- *** -->
<!-- Novas referências e ideias -->

<!-- * Criação de questões -->

<!-- Pip Arnold & Christine Franklin (2021) What Makes a Good Statistical Question?, Journal of Statistics and Data Science Education, 29:1, 122-130, DOI: 10.1080/26939169.2021.1877582 -->

<!-- Refletem acerca de elementos para criação de questões que avaliem a compreensão dos conceitos e linguagem estatística de maneira mais completa. -->

<!-- *** -->
<!-- * Integridade acadêmica -->

<!-- Da mesma autora, Workshop IASE "Using the R/exams package for an efficient workflow to design, produce and mark online assessments while safeguarding the academic integrity" https://www.isi-web.org/events/node-2205 -->

***


<a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc/4.0/">Creative Commons Attribution-NonCommercial 4.0 International License</a>.
